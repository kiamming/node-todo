{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-family: Arial; font-size:3.75em;color:red; font-style:bold\"><br>\n",
    "Beautiful Soup Test</p>\n",
    "\n",
    "<span style=\"font-size:2em;\">This section is composed of 3 parts with a total of 40 marks. \n",
    "You will be given empty code cells and the expected output . \n",
    "The final submission will be this jupyter notebook with the code filled in.\n",
    "\n",
    "<span style=\"font-size:1.5em;\">1. Parsing paragraphs (16 marks)\n",
    "\n",
    "<span style=\"font-size:1.5em;\">2. Parsing tables (8 marks)\n",
    "\n",
    "<span style=\"font-size:1.5em;\">3. Parsing multiple pages (16 marks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">i) Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">ii) The test will be based off four webpages. You can download the webpages from Polymall in the folder called plants.\n",
    "It will contain 4 html files and 2 folders (styles and images):\n",
    "\n",
    "<span style=\"font-size:1.5em;\">1. index.html\n",
    "\n",
    "<span style=\"font-size:1.5em;\">2. orchid.html\n",
    "\n",
    "<span style=\"font-size:1.5em;\">3. pitcherPlant.html\n",
    "\n",
    "<span style=\"font-size:1.5em;\">4. rafflesia.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">1.Parsing paragraphs</h1>\n",
    "\n",
    "<span style=\"font-size:2em;\">1.1 Use BeautifulSoup to parse orchid.html. (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(open('orchid.html'), \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">1.2 Print out the text in the span tag with the class genus. (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orchis\n"
     ]
    }
   ],
   "source": [
    "# find the correct element and store it into plantGenus, \n",
    "# then print out the text inside \n",
    "plantGenus = soup.find(\"span\", class_=\"genus\")\n",
    "print(plantGenus.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">1.3 Get all the siblings after the element with an id of priDet, \n",
    "and print out the id(s) of these siblings if it/they exist. (3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secDet\nniceLine\n"
     ]
    }
   ],
   "source": [
    "# find the element with an id of priDet\n",
    "priDet = soup.find(True, {\"id\": \"priDet\"})\n",
    "\n",
    "# find the next siblings\n",
    "siblings = priDet.findNextSiblings()\n",
    "\n",
    "# use a for loop to print out the ids of siblings who have ids.\n",
    "for sibling in siblings:\n",
    "    if sibling.get(\"id\") is not None:\n",
    "        print(sibling.get(\"id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">1.4 Find all span elements with the class similar, store them in a variable called allSimilar, and print them out. (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"sameKind similar\">edelweiss</span>, <span class=\"similar sameKind\">rose</span>, <span class=\"similar\" name=\"interesting\">Asteraceae</span>]\n"
     ]
    }
   ],
   "source": [
    "# Find all span elements with the class similar and store it into the variable allSimilar\n",
    "allSimilar = soup.find_all(\"span\", class_=\"similar\")\n",
    "print(allSimilar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">1.5 Create an empty list called allSimilarList, and append to it all the text in the elements in allSimilar. (3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edelweiss', 'rose', 'Asteraceae']\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list allSimilarList\n",
    "allSimilarList = []\n",
    "# Use a for loop to extract the text in every element in allSimilar\n",
    "for item in allSimilar:\n",
    "    allSimilarList.append(item.text)\n",
    "print(allSimilarList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">1.6 Find span elements that contain both the class sameKind and similar. (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"sameKind similar\">edelweiss</span>, <span class=\"similar sameKind\">rose</span>]\n"
     ]
    }
   ],
   "source": [
    "# Print out span elements with both the class sameKind and similar\n",
    "print(soup.select(\"span.sameKind.similar\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">1.7 Print the span element that has for name \"interesting\" and has the class \"similar\". (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"similar\" name=\"interesting\">Asteraceae</span>\n"
     ]
    }
   ],
   "source": [
    "# Print out the span element that has for name \"interesting\" and has the class \"similar\".\n",
    "print(soup.find(\"span\", {\"name\":\"interesting\", \"class\":\"similar\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">1.8 Print the name of the element with the id priDet. (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primaryDetails\n"
     ]
    }
   ],
   "source": [
    "#Print the name of the element with the id priDet.\n",
    "print(soup.find(True, {\"id\": \"priDet\"})[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">1.9 Print all the elements containing the text \"Along\" or \"along\". (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['. The designation of Vanda Miss Joaquim var. Agnes as Singaporeâ€™s national flower in 15 April 1981 was part of an overall effort to foster national pride and identity. Singapore has the unique distinction of being the only nation to have a hybrid as its national flower. Singapore has the unique distinction of being the only nation to have a hybrid as its national flower. Popular national flowers along with Singapore include the ', '\", from the appearance of the paired subterranean tuberoids. Along with the ']\n"
     ]
    }
   ],
   "source": [
    "# Print all elements that contain the text \"Along\" or \"along\" \n",
    "found_along = soup.find_all(text=re.compile(\"[A,a]long\"))\n",
    "print(found_along)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">2.Parsing tables</h1>\n",
    "\n",
    "<span style=\"font-size:2em;\">2.1 Find all the td tags within the tr tag of the thead of the only table in the page. Print out the td tags. (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<td>Common name  </td>, <td>Average length  </td>]\n"
     ]
    }
   ],
   "source": [
    "# Suggestion: chain the following searches\n",
    "# i) find table\n",
    "# ii) find thead\n",
    "# iii) find tr\n",
    "# iv) find all td\n",
    "tds = soup.find(\"table\").find(\"thead\").find(\"tr\").find_all(\"td\")\n",
    "\n",
    "# Print out the td tags\n",
    "print(tds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">2.2 Create an empty list called headings and append the text (with whitespace stripped away) in the td tags found in i). Print out the list. (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Common name', 'Average length']\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list called headings\n",
    "headings = []\n",
    "# Loop through the tds, strip away the whitespace from the text, and append it to headings\n",
    "for td in tds:\n",
    "    headings.append(td.text.strip())\n",
    "\n",
    "# Print headings out\n",
    "print(headings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">2.3 Find all the tr tags of the tbody of the only table in the page. Print out the tr tags. (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tr title=\"Moth Orchid\">\n<td><a href=\"https://en.wikipedia.org/wiki/Phalaenopsis\">Moth Orchid</a>\n</td>\n<td>\n\t5 cm</td>\n</tr>, <tr title=\"Naked Man Orchid\">\n<td><a href=\"https://en.wikipedia.org/wiki/Orchis_italica\">Naked Man Orchid</a>\n</td>\n<td>\n\t24 cm</td>\n</tr>, <tr title=\"Dancing Orchid\">\n<td><a href=\"https://en.wikipedia.org/wiki/Impatiens\">Dancing Girls Orchid</a>\n</td>\n<td>\n\t13 cm</td>\n</tr>]\n"
     ]
    }
   ],
   "source": [
    "trs = soup.find(\"table\").find(\"tbody\").find_all(\"tr\")\n",
    "print(trs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">2.4 Extracting data from tables\n",
    "\n",
    "<span style=\"font-size:1.5em;\">* Loop through the tr tags found and get all the td tags in each tr tag. (1 mark) \n",
    "\n",
    "<span style=\"font-size:1.5em;\">* If the td has an a tag, print out the href attribute. (1 mark)\n",
    "\n",
    "<span style=\"font-size:1.5em;\">* You also need to print out the text in the td after trimming all whitespace out. (1 mark) \n",
    "\n",
    "<span style=\"font-size:1.5em;\">* You also need to print out the loop number with a colon behind. (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\nhttps://en.wikipedia.org/wiki/Phalaenopsis\nMoth Orchid\n5 cm\n\n\n2:\nhttps://en.wikipedia.org/wiki/Orchis_italica\nNaked Man Orchid\n24 cm\n\n\n3:\nhttps://en.wikipedia.org/wiki/Impatiens\nDancing Girls Orchid\n13 cm\n\n\n"
     ]
    }
   ],
   "source": [
    "for index, tr in enumerate(trs):\n",
    "    print(str(index+1)+\":\")\n",
    "    for td in tr.find_all(\"td\"):\n",
    "        if td.find(\"a\") is not None:\n",
    "            print(td.find(\"a\")[\"href\"])\n",
    "        print(td.text.strip())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:2em;color:#2467C0\">3.Parsing multiple pages</h1>\n",
    "\n",
    "<span style=\"font-size:2em;\">3.1 Create a new BeautifulSoup object named indexSoup from \"index.html\". (1 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexSoup = BeautifulSoup(open('index.html'), \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">3.2 Getting required ul \n",
    "\n",
    "<span style=\"font-size:1.5em;\">* Find the span element with an id of favList.\n",
    "\n",
    "<span style=\"font-size:1.5em;\">* Find its parent.\n",
    "\n",
    "<span style=\"font-size:1.5em;\">* Find the first of the parent's next siblings and store it into the variable ul. Print it out.\n",
    "(3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul>\n<li><b>My list of cool plants</b>\n<ul>\n<li><a href=\"orchid.html\" title=\"Orchids\">Funny Orchids</a></li>\n<li><a href=\"rafflesia.html\" title=\"Rafflesia\">Corpse Flower</a></li>\n<li><a class=\"incomplete\" href=\"#\" title=\"Ophrys apifera\">Bee Chrysanthemum</a></li>\n<li><a href=\"pitcherPlant.html\" title=\"Nepenthaceae\">Pitcher Plant</a></li>\n</ul>\n</li>\n</ul>\n"
     ]
    }
   ],
   "source": [
    "ul = indexSoup.find(\"span\", {\"id\":\"favList\"}).findParent().findNextSiblings()[0]\n",
    "print(ul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">3.3 Create an empty list called links. Using a for loop, save all the hypertext references except for the dummy value “#” i.e. value of the href attributes inside the variable ul. (3 marks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orchid.html', 'rafflesia.html', 'pitcherPlant.html']\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "for li in ul.find(\"ul\").find_all(\"li\"):\n",
    "    currentHREF = li.find(\"a\")['href']\n",
    "    if currentHREF != \"#\":\n",
    "        links.append(currentHREF)\n",
    "\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:2em;\">3.4 Create an empty list df. Create also an empty list headings. Using a for loop to iterate through links,  extract the headings (stripped of whitespace) of the table in one of the page into headings, as well as extract into df \n",
    "\n",
    "<span style=\"font-size:1.5em;\">* the url, \n",
    "\n",
    "<span style=\"font-size:1.5em;\">* the common name, \n",
    "\n",
    "<span style=\"font-size:1.5em;\">* the average length of all the plants in all 3 pages with hyperlinks in index.html. \n",
    "\n",
    "<span style=\"font-size:1.5em;\">Print out both headings and df. (9 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['URL', 'Common name', 'Average length']\n[['https://en.wikipedia.org/wiki/Phalaenopsis', 'Moth Orchid', '5 cm'], ['https://en.wikipedia.org/wiki/Orchis_italica', 'Naked Man Orchid', '24 cm'], ['https://en.wikipedia.org/wiki/Impatiens', 'Dancing Girls Orchid', '13 cm'], ['https://en.wikipedia.org/wiki/Rafflesia_arnoldii', 'Rafflesia arnoldii', '106 cm'], ['https://en.wikipedia.org/wiki/Rafflesia_cantleyi', 'Rafflesia cantleyi', '87 cm'], ['https://en.wikipedia.org/wiki/Rafflesia_keithii', 'Rafflesia keithii', '80 cm'], ['https://en.wikipedia.org/wiki/Pitcher_plant', 'Pitcher plant', '12 cm'], ['https://en.wikipedia.org/wiki/Venus_flytrap', 'Venus flytrap', '8 cm'], ['https://en.wikipedia.org/wiki/Bladderwort', 'Bladderwort', '28 cm']]\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "headings = []\n",
    "\n",
    "for indexInLink, link in enumerate(links):\n",
    "    eachSoup = BeautifulSoup(open(link), \"html.parser\")\n",
    "    \n",
    "    trs = eachSoup.find(\"table\").find(\"tbody\").find_all(\"tr\")\n",
    "    for indexInTR, tr in enumerate(trs):\n",
    "        eachRow = []\n",
    "        if indexInLink == 1 and indexInTR == 1:\n",
    "            theadTD = eachSoup.find(\"table\").find(\"thead\").find_all(\"td\")\n",
    "            for headingTD in theadTD:\n",
    "                headings.append(headingTD.text.strip())\n",
    "            \n",
    "            #add the column heading \"URL\" to the front of headings\n",
    "            headings.insert(0,\"URL\")\n",
    "            print(headings)\n",
    "                \n",
    "        for td in tr.find_all(\"td\"):\n",
    "            if td.find(\"a\") is not None:\n",
    "                eachRow.append(td.find(\"a\")[\"href\"])\n",
    "            eachRow.append(td.text.strip())\n",
    "        \n",
    "        df.append(eachRow)\n",
    "        \n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
